{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26ff145-ebff-47e4-a071-b3421a46732d",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad0a97b-baed-4743-85b4-fddee17ab44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/0 (e.g. pd.read_csv)\n",
    "import re # for regex\n",
    "import unicodedata\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdf14c0-67d3-4f7e-8634-aabd48aaa7ac",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55fea1-a143-40f8-a295-71f05997630d",
   "metadata": {},
   "source": [
    "## Normalizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5599a00e-d0aa-42a2-b77e-4e2a94d12d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(s):\n",
    "    \"\"\"\n",
    "    Normaliza o texto colocando em caixa baixa e removendo acentuação/pontuação.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : str\n",
    "        Entrada de texto.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Texto normalizado. Se `s` não for uma string, retorna inalterado.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> norm(\"Árvore\")\n",
    "    'arvore'\n",
    "\n",
    "    >>> norm(\"Fomos à escola ontem, Fernando não estava lá.\")\n",
    "    'fomos a escola ontem fernando nao estava la'\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "        \n",
    "    s = s.lower()\n",
    "    s = s.replace(\"-\", \" \")\n",
    "    \n",
    "    s = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "  \n",
    "    return re.sub(r\"[^A-Za-zÀ-ÿ ]+\", \"\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c952dd-efaa-47e0-8302-3f70472433e1",
   "metadata": {},
   "source": [
    "# Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77757810-ae30-4e1b-9714-1d98b4ea2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_words = pd.read_csv('../data/sentilex_v1.0.0.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adaebfe-3b1e-42f0-9e1c-62556b67d742",
   "metadata": {},
   "source": [
    "# Entrada de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbee90e-d5f6-42d2-b37f-4d931b0c3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_neutral = \"\"\"O evento começou pontualmente às 10h da manhã, conforme anunciado no cronograma. O palestrante principal falou por exatos 45 minutos, cobrindo os tópicos listados na descrição da palestra. Após a apresentação, os participantes foram direcionados ao salão adjacente para o intervalo. A organização informou que a próxima sessão começará em 15 minutos.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b556fe8-52d3-40e4-8359-cd4e480f36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_positive = \"\"\"A experiência de hoje foi absolutamente fantástica! Desde o primeiro momento, a equipe demonstrou um profissionalismo e uma simpatia incríveis, superando todas as minhas expectativas. O produto não é apenas bom, é maravilhoso e funciona perfeitamente. A qualidade é evidente em cada detalhe. Estou genuinamente impressionado e muito satisfeito com o resultado. Com certeza recomendo a todos; foi uma escolha excelente e valeu cada centavo!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f62fb0-747e-46fd-b24e-6fcae10c0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_negative = \"\"\"Minha experiência hoje foi absolutamente terrível. Desde o início, o atendimento demonstrou um descaso e uma falta de profissionalismo inacreditáveis, frustrando todas as minhas expectativas. O produto não é apenas ruim, é péssimo e falha constantemente. A baixa qualidade é evidente em cada detalhe. Estou genuinamente decepcionado e muito insatisfeito com o resultado. Com certeza não recomendo a ninguém; foi uma escolha horrível e um desperdício de dinheiro.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a22b6922-df13-425c-9c28-efe463ee1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_text = \"É bem comum as pessoas terem gostos próprios.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78dab6ae-0e28-457f-9ac6-5b6f06b88b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_test_1p = \"Serviço rápido, funcionários atentos, resolução eficiente do que eu precisava.\"\n",
    "\n",
    "txt_test_1ng = \"Produto chegou quebrado, atendimento falhou em resolver e a experiência inteira foi desgastante.\"\n",
    "\n",
    "txt_test_1nt = \"A entrega ocorreu no prazo, sem surpresa boa ou ruim, exatamente o esperado.\"\n",
    "\n",
    "txt_test_2p = \"A atualização recente melhorou desempenho, reduziu erros e deixou o uso mais fluido.\"\n",
    "\n",
    "txt_test_2ng = \"O processo ficou confuso, documentação incompleta e resultados abaixo do que foi prometido.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af7040-23af-443c-9dbb-5fb11d8a8d98",
   "metadata": {},
   "source": [
    "# Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f16cb-262a-48a1-a9d2-624c193890e8",
   "metadata": {},
   "source": [
    "Aplica a normalização nos textos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d7d12d4-a681-43ec-b870-27b80f0f752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.texts = df_texts.texts.apply(norm).astype(\"string\")\n",
    "df_class_words.word = df_class_words.word.apply(norm).astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d5aceb4-0d31-4d4f-a202-b788a74e358b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>polarity_n0</th>\n",
       "      <th>polarity_n1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a vontade</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abafado</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abafante</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abaixado</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalado</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7009</th>\n",
       "      <td>zombeteiro</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>zonzeira</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>zonzo</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>zote</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>zumbidor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  polarity_n0  polarity_n1\n",
       "0      a vontade          1.0          NaN\n",
       "1        abafado         -1.0          NaN\n",
       "2       abafante         -1.0          NaN\n",
       "3       abaixado         -1.0          NaN\n",
       "4        abalado         -1.0          NaN\n",
       "...          ...          ...          ...\n",
       "7009  zombeteiro         -1.0          NaN\n",
       "7010    zonzeira         -1.0          NaN\n",
       "7011       zonzo         -1.0          NaN\n",
       "7012        zote         -1.0          NaN\n",
       "7013    zumbidor         -1.0          NaN\n",
       "\n",
       "[7014 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaaedf4-3942-47be-a9c6-ad0e1279b2bf",
   "metadata": {},
   "source": [
    "Tokeniza o texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d2ec4a2-291c-439f-b39f-eb27a0a65fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "text = df_texts.texts[1]\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extraindo os tokens\n",
    "tokens = [token.text for token in doc]\n",
    "df_text_tokens = pd.DataFrame(tokens)\n",
    "df_text_tokens.columns = ['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fd47f18-5336-49d1-b741-fd02f05da4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hoje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word\n",
       "0            a\n",
       "1  experiencia\n",
       "2           de\n",
       "3         hoje\n",
       "4          foi"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79667f-ca04-4394-a70b-d92880312c0f",
   "metadata": {},
   "source": [
    "# Mesclando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0dcf943-82b3-4b4f-b511-0c076bbbd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df_text_tokens.merge(\n",
    "    df_class_words[['word', 'polarity_n0','polarity_n1']],\n",
    "    on='word',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e143a51-10af-46fa-9ed2-1d1d72a1cdf1",
   "metadata": {},
   "source": [
    "# Removendo valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0b7a655-0923-4bf1-bbb1-152c03bd3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.dropna(subset=['polarity_n0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c0e3d-407e-4035-8344-af7253ab3890",
   "metadata": {},
   "source": [
    "# Contando polaridades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05a51ae5-3969-43be-a78a-af21a901dbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity_n0\n",
       "-1    0\n",
       " 0    1\n",
       " 1    7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem = merged['polarity_n0'].value_counts().reindex([-1, 0, 1], fill_value=0)\n",
    "contagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625579e-567b-4ace-ae03-c1f402a1c54d",
   "metadata": {},
   "source": [
    "# Checando o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19540de2-a214-4ee9-a1a8-fb0599476524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivo\n"
     ]
    }
   ],
   "source": [
    "if (contagem == contagem.max()).sum() > 1:\n",
    "    resultado = None     # empate\n",
    "else:\n",
    "    resultado = contagem.idxmax()\n",
    "\n",
    "if resultado == 1:\n",
    "    print(\"positivo\")\n",
    "elif resultado == -1:\n",
    "    print(\"negativo\")\n",
    "else :\n",
    "    print(\"neutro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e4d36-4333-43b5-b9ce-66f62a05c4ce",
   "metadata": {},
   "source": [
    "# Juntando tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94ca9f32-5aa3-4f52-8c7e-f4335632755a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivo\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "text = txt_test_1p\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extraindo os tokens\n",
    "tokens = [token.text for token in doc]\n",
    "df_text_tokens = pd.DataFrame(tokens)\n",
    "df_text_tokens.columns = ['word']\n",
    "\n",
    "merged = df_text_tokens.merge(\n",
    "    df_class_words[['word', 'polarity_n0','polarity_n1']],\n",
    "    on='word',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "merged = merged.dropna(subset=['polarity_n0'])\n",
    "\n",
    "contagem = merged['polarity_n0'].value_counts().reindex([-1, 0, 1], fill_value=0)\n",
    "contagem\n",
    "\n",
    "if (contagem == contagem.max()).sum() > 1:\n",
    "    resultado = None     # empate\n",
    "else:\n",
    "    resultado = contagem.idxmax()\n",
    "\n",
    "if resultado == 1:\n",
    "    print(\"positivo\")\n",
    "elif resultado == -1:\n",
    "    print(\"negativo\")\n",
    "else :\n",
    "    print(\"neutro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa653e97-217d-4fcb-97ce-5ecf12c8685c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
