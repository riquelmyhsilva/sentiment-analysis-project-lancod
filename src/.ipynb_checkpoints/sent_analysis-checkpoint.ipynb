{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26ff145-ebff-47e4-a071-b3421a46732d",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad0a97b-baed-4743-85b4-fddee17ab44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/0 (e.g. pd.read_csv)\n",
    "import re # for regex\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn. feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn. naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdf14c0-67d3-4f7e-8634-aabd48aaa7ac",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55fea1-a143-40f8-a295-71f05997630d",
   "metadata": {},
   "source": [
    "## Normalizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5599a00e-d0aa-42a2-b77e-4e2a94d12d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(s):\n",
    "    \"\"\"\n",
    "    Normaliza o texto colocando em caixa baixa e removendo acentuação/pontuação.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : str\n",
    "        Entrada de texto.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Texto normalizado. Se `s` não for uma string, retorna inalterado.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> norm(\"Árvore\")\n",
    "    'arvore'\n",
    "\n",
    "    >>> norm(\"Fomos à escola ontem, Fernando não estava lá.\")\n",
    "    'fomos a escola ontem fernando nao estava la'\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "        \n",
    "    s = s.lower()\n",
    "    s = s.replace(\"-\", \" \")\n",
    "    \n",
    "    s = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "  \n",
    "    return re.sub(r\"[^A-Za-zÀ-ÿ ]+\", \"\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c952dd-efaa-47e0-8302-3f70472433e1",
   "metadata": {},
   "source": [
    "# Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77757810-ae30-4e1b-9714-1d98b4ea2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_words = pd.read_csv('../data/sentilex_v1.0.0.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "247594f6-a3d8-424f-92f1-c3f7bd8b4e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>polarity_n0</th>\n",
       "      <th>polarity_n1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>à-vontade</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abafado</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abafante</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abaixado</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalado</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7009</th>\n",
       "      <td>zombeteiro</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>zonzeira</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>zonzo</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>zote</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>zumbidor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  polarity_n0  polarity_n1\n",
       "0      à-vontade          1.0          NaN\n",
       "1        abafado         -1.0          NaN\n",
       "2       abafante         -1.0          NaN\n",
       "3       abaixado         -1.0          NaN\n",
       "4        abalado         -1.0          NaN\n",
       "...          ...          ...          ...\n",
       "7009  zombeteiro         -1.0          NaN\n",
       "7010    zonzeira         -1.0          NaN\n",
       "7011       zonzo         -1.0          NaN\n",
       "7012        zote         -1.0          NaN\n",
       "7013    zumbidor         -1.0          NaN\n",
       "\n",
       "[7014 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adaebfe-3b1e-42f0-9e1c-62556b67d742",
   "metadata": {},
   "source": [
    "# Entrada de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbee90e-d5f6-42d2-b37f-4d931b0c3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_neutral = \"\"\"O evento começou pontualmente às 10h da manhã, conforme anunciado no cronograma. O palestrante principal falou por exatos 45 minutos, cobrindo os tópicos listados na descrição da palestra. Após a apresentação, os participantes foram direcionados ao salão adjacente para o intervalo. A organização informou que a próxima sessão começará em 15 minutos.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b556fe8-52d3-40e4-8359-cd4e480f36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_positive = \"\"\"A experiência de hoje foi absolutamente fantástica! Desde o primeiro momento, a equipe demonstrou um profissionalismo e uma simpatia incríveis, superando todas as minhas expectativas. O produto não é apenas bom, é maravilhoso e funciona perfeitamente. A qualidade é evidente em cada detalhe. Estou genuinamente impressionado e muito satisfeito com o resultado. Com certeza recomendo a todos; foi uma escolha excelente e valeu cada centavo!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f62fb0-747e-46fd-b24e-6fcae10c0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_negative = \"\"\"Minha experiência hoje foi absolutamente terrível. Desde o início, o atendimento demonstrou um descaso e uma falta de profissionalismo inacreditáveis, frustrando todas as minhas expectativas. O produto não é apenas ruim, é péssimo e falha constantemente. A baixa qualidade é evidente em cada detalhe. Estou genuinamente decepcionado e muito insatisfeito com o resultado. Com certeza não recomendo a ninguém; foi uma escolha horrível e um desperdício de dinheiro.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a22b6922-df13-425c-9c28-efe463ee1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_text = \"É bem comum as pessoas terem gostos próprios.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7b07d4-4ea2-46b1-8e60-b486e53e37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_texts = {\"texts\":[text_neutral, text_positive, text_negative, ig_text]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af7040-23af-443c-9dbb-5fb11d8a8d98",
   "metadata": {},
   "source": [
    "# Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d119b4-a720-4e1b-8f65-79172d79de86",
   "metadata": {},
   "source": [
    "Cria um dataframe com os diferentes tipos de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44df2faf-f02a-4ba7-8a9e-b3a287ec222b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O evento começou pontualmente às 10h da manhã,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A experiência de hoje foi absolutamente fantás...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Minha experiência hoje foi absolutamente terrí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>É bem comum as pessoas terem gostos próprios.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts\n",
       "0  O evento começou pontualmente às 10h da manhã,...\n",
       "1  A experiência de hoje foi absolutamente fantás...\n",
       "2  Minha experiência hoje foi absolutamente terrí...\n",
       "3      É bem comum as pessoas terem gostos próprios."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts = pd.DataFrame(dict_texts) \n",
    "df_texts[\"texts\"].astype(\"string\")\n",
    "df_texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f16cb-262a-48a1-a9d2-624c193890e8",
   "metadata": {},
   "source": [
    "Aplica a normalização nos textos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d7d12d4-a681-43ec-b870-27b80f0f752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.texts = df_texts.texts.apply(norm).astype(\"string\")\n",
    "df_class_words.word = df_class_words.word.apply(norm).astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d5aceb4-0d31-4d4f-a202-b788a74e358b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>polarity_n0</th>\n",
       "      <th>polarity_n1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a vontade</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abafado</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abafante</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abaixado</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalado</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7009</th>\n",
       "      <td>zombeteiro</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>zonzeira</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>zonzo</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>zote</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>zumbidor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  polarity_n0  polarity_n1\n",
       "0      a vontade          1.0          NaN\n",
       "1        abafado         -1.0          NaN\n",
       "2       abafante         -1.0          NaN\n",
       "3       abaixado         -1.0          NaN\n",
       "4        abalado         -1.0          NaN\n",
       "...          ...          ...          ...\n",
       "7009  zombeteiro         -1.0          NaN\n",
       "7010    zonzeira         -1.0          NaN\n",
       "7011       zonzo         -1.0          NaN\n",
       "7012        zote         -1.0          NaN\n",
       "7013    zumbidor         -1.0          NaN\n",
       "\n",
       "[7014 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "352ca220-6f57-4f64-9a35-8e13ba0ab613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rique\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rique\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\rique\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['evento',\n",
       " 'comecou',\n",
       " 'pontualmente',\n",
       " 'h',\n",
       " 'manha',\n",
       " 'conforme',\n",
       " 'anunciado',\n",
       " 'cronograma',\n",
       " 'palestrante',\n",
       " 'principal',\n",
       " 'falou',\n",
       " 'exatos',\n",
       " 'minutos',\n",
       " 'cobrindo',\n",
       " 'topicos',\n",
       " 'listados',\n",
       " 'descricao',\n",
       " 'palestra',\n",
       " 'apos',\n",
       " 'apresentacao',\n",
       " 'participantes',\n",
       " 'direcionados',\n",
       " 'salao',\n",
       " 'adjacente',\n",
       " 'intervalo',\n",
       " 'organizacao',\n",
       " 'informou',\n",
       " 'proxima',\n",
       " 'sessao',\n",
       " 'comecara',\n",
       " 'minutos']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def rem_stopwords(text):\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    words = word_tokenize(text)\n",
    "    return [w for w in words if w not in stop_words]\n",
    "\n",
    "df_texts.texts = df_texts.texts.apply(rem_stopwords)\n",
    "df_texts.texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaaedf4-3942-47be-a9c6-ad0e1279b2bf",
   "metadata": {},
   "source": [
    "Tokeniza o texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a50963bd-2789-4d5a-9369-b662fb38f72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'event comec pontual h manh conform anunc cronogram palestr principal fal exat minut cobr topic list descrica palestr apos apresentaca particip direcion sala adjacent interval organizaca inform proxim sessa comec minut'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_txt(text):\n",
    "    ss = SnowballStemmer('portuguese')\n",
    "    return \" \".join([ss.stem(w) for w in text])\n",
    ",\n",
    "df_texts.texts = df_texts.texts.apply(stem_txt)\n",
    "df_texts.texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba819ca9-f4f8-40db-9571-d772f5cccd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_class_words = df_class_words.copy()\n",
    "df_test_class_words.word = df_test_class_words.word.apply(rem_stopwords)\n",
    "df_test_class_words.word = df_test_class_words.word.apply(stem_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6210cf54-5194-4f06-a8af-1dfca196f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_class_words[df_test_class_words[\"polarity_n0\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda0d3e-0c6e-41a9-aa5b-5e0c736f9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_class_words = df_test_class_words.dropna(subset=[\"polarity_n0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce5d10-c02b-48d8-bb7e-8f7e1dbcfb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df_test_class_words.iloc[:,0].values)\n",
    "y = np.array(df_test_class_words.polarity_n0.values)\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "X = cv.fit_transform(df_test_class_words.word).toarray()\n",
    "print(\"X.shape = \", X.shape)\n",
    "print(\"y.shape = \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419006ba-f8da-4e32-9856-877ae055b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, testx, trainy, testy = train_test_split(X,y, test_size = 0.2, random_state = 9)\n",
    "print(\"Train shapes : X = {}, y = {}\".format(trainx.shape, trainy.shape))\n",
    "print(\"Test shapes : X = {}, y = {}\".format(testx.shape, testy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc0d95-b065-4029-a110-fdd3f71ec532",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb, mnb, bnb = GaussianNB(), MultinomialNB(alpha = 1.0, fit_prior = True), BernoulliNB(alpha = 1.0, fit_prior = True)\n",
    "gnb.fit(trainx, trainy)\n",
    "mnb.fit(trainx, trainy)\n",
    "bnb.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12d89d-fa1c-4ff4-b08d-fe512449542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypg = gnb.predict(testx)\n",
    "ypm = mnb.predict(testx)\n",
    "ypb = bnb.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042709e5-d74a-4438-ad96-a81425792a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gaussian = \", accuracy_score(testy, ypg))\n",
    "print(\"Multinomial = \", accuracy_score(testy, ypm))\n",
    "print(\"Bernoulli = \", accuracy_score(testy, ypb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3337e30-2ac1-494b-bdc0-3864f8d90862",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bnb, open('model1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ec4a2-291c-439f-b39f-eb27a0a65fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "text = df_texts.texts[0]\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extraindo os tokens\n",
    "tokens = [token.text for token in doc]\n",
    "df_text_tokens = pd.DataFrame(tokens)\n",
    "df_text_tokens.columns = ['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd47f18-5336-49d1-b741-fd02f05da4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79667f-ca04-4394-a70b-d92880312c0f",
   "metadata": {},
   "source": [
    "# Mesclando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcf943-82b3-4b4f-b511-0c076bbbd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df_text_tokens.merge(\n",
    "    df_class_words[['word', 'polarity_n0','polarity_n1']],\n",
    "    on='word',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e143a51-10af-46fa-9ed2-1d1d72a1cdf1",
   "metadata": {},
   "source": [
    "# Removendo valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7a655-0923-4bf1-bbb1-152c03bd3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.dropna(subset=['polarity_n0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c0e3d-407e-4035-8344-af7253ab3890",
   "metadata": {},
   "source": [
    "# Contando polaridades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a51ae5-3969-43be-a78a-af21a901dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem = merged['polarity_n0'].value_counts().reindex([-1, 0, 1], fill_value=0)\n",
    "contagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625579e-567b-4ace-ae03-c1f402a1c54d",
   "metadata": {},
   "source": [
    "# Checando o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19540de2-a214-4ee9-a1a8-fb0599476524",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (contagem == contagem.max()).sum() > 1:\n",
    "    resultado = None     # empate\n",
    "else:\n",
    "    resultado = contagem.idxmax()\n",
    "\n",
    "if resultado == 1:\n",
    "    print(\"positivo\")\n",
    "elif resultado == -1:\n",
    "    print(\"negativo\")\n",
    "else :\n",
    "    print(\"neutro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
